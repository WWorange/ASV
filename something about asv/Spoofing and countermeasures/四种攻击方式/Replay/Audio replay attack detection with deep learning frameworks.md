# Audio replay attack detection with deep learning frameworks

## 摘要

如今，欺骗检测已成为自动说话者验证领域中的优先研究领域之一。 2015年自动扬声器验证欺骗和对策（ASVspoof）挑战赛的成功证实了在检测基于语音合成和语音转换技术的未预料到的欺骗试验中的令人印象深刻的前景。但是，针对重播欺骗攻击的研究很少，非专业模仿者更可能使用这种研究。本文介绍了为ASVspoof 2017提交的语音技术中心（STC）防欺骗系统，该系统着重于重放攻击检测。在这里，我们研究了深度学习方法解决上述任务的效率。在Challenge语料库上获得的实验结果表明，在欺骗检测质量方面，所选方法优于当前最新的基线系统。我们的主要系统在语料库的评估部分产生了6.73％的EER，比ASVspoof 2017基准系统相对提高了72％。

## Introduction

在过去的十年中，生物识别技术取得了巨大的进步。 它在我们的日常生活中变得越来越广泛。 语音生物识别技术依其权利仍然是该领域的优先研究方向之一。 自动扬声器验证（ASV）系统由于其可靠性，便利性，低成本和提供的安全性而积极投放市场。 ASV系统广泛用于呼叫中心，交互式语音响应（IVR）系统和移动应用程序。 它们的高性能允许将它们用于保护更有价值的数据，例如机密帐户信息或交易确认。 随着安全数据重要性的日益提高，对ASV系统欺骗的风险评估的需求也在增加[1]。

根据[2]，ASV系统的麦克风和传输级别的攻击通常构成最大的威胁。 欺骗攻击有四种类型：模拟，重播音频（RA），语音合成（SS）和语音转换（VC）[3]。 ASV系统本身可以轻松解决假冒的检测问题[4]。 2015年自动扬声器验证欺骗（ASVspoof）挑战[5]在检测VC和SS方面显示了令人印象深刻的结果。 与这些欺骗类型相比，重播攻击在音频信号处理中不需要其他知识，并且更有可能被非专业模仿者使用。 但是，通常在受限条件下考虑此问题。 在这方面，开发能够在各种条件下工作的重放攻击检测器的任务非常重要。

ASVspoof Challenge 2017 [6]专注于在“看不见”的情况下，针对文本相关的说话者验证系统的“独立”重放音频检测任务。 本文介绍了为ASVspoof 2017提交的语音技术中心（STC）反欺骗系统。

这项研究的主要目的是研究有前途的卷积神经网络（CNN）方法解决RA检测问题的效率。 CNN在分类和识别任务（例如视频分类[7]，图像分类[8、9]，面部识别[10]）中的成功是将此类方法应用于ASV反欺骗任务的强大动力。

在[11]中，作者研究了应用于ASVspoof 2015语料库的VC和SS欺骗检测的深度学习框架。 深度神经网络（DNN），CNN和递归神经网络（RNN）架构被证明对这项任务非常有效。 作者还提出了CNN + RNN架构，并展示了其最新的性能。

[12]的作者提出将时态CNN架构用于VC和SS欺骗语音检测，并且在ASVspoof 2015语料库上也取得了显著成果。

CNN通常用作统一形状数据（例如图像）的鲁棒特征提取器。 通过在时频域中表示输入信号，可以将该方法扩展到各种音频信号分类任务。 但是，应特别注意CNN输入数据应具有统一形式的事实。 在这种情况下，有必要为每种发声要求统一的时频（T-F）形状，或者将开窗程序应用于具有固定窗口大小的时频数据。

许多[13、14、15]著名的体系结构在图像分类任务中显示出良好的效果。 在这项工作中，我们基于最大功能图激活（MFM）的使用，利用简化版的Light CNN架构[16]，该功能基于最大输出激活功能[17]。 具有MFM的神经网络能够选择对于解决任务至关重要的功能。 根据我们的假设，这种类型的网络可以成功实现音频分类任务，尤其是反欺骗。

##  Baseline systems

###  ASVspoof baseline system

本研究中使用的基准系统是ASVspoof 2017的组织者提出的最新RA检测器的参考实现。该系统基于恒定Q变换技术，该技术广泛用于音乐信号处理和 用于基于SS和VC的欺骗攻击检测[18]。

在该系统的前端，根据图1中的方案估算常数Q变换倒频谱系数（CQCC）。后端对真实语音和伪语音使用标准的2类高斯混合模型（GMM）分类器。 对于每种话语，从两个模型中都获得了对数似然度得分，最终系统得分被计算为对数似然率。

作为替代方法，我们考虑基线系统，以及对数功率谱和倒谱的均值和方差归一化（MVN）附加步骤。

###  I-vector based system

受针对ASVspoof 2015提出的基于i向量的SS和VC欺骗检测系统的成功启发，我们构建了基于i向量方法的RA检测系统[20]。
		我们尝试了ASVspoof 2015 [19]中使用的不同声学特征。 该系统使用线性预测倒谱系数（LPCC），根据我们的观察，它为RA检测提供了最佳结果。 提取所有语音的I向量，并将其用作SVM分类器的输入。
		这两个基准系统的实现特征将在第4节中详细介绍。

##  Deep learning frameworks

在本节中，我们介绍用于RA欺骗检测的深度学习方法，用于高级特征提取和作为端到端解决方案。

###  Front-End

我们使用通过常数Q变换（CQT）[18]和快速傅里叶变换（FFT）获得的归一化对数功率幅度谱作为CNN输入声学特征，如图2所示。

我们考虑了两种获得特征的统一时频（T-F）形状的技术。 其中之一将沿时间轴以固定大小截断频谱。 在此过程中，如有必要，短文件通过重复其内容来扩展以匹配所需的长度。 另一种技术使用具有固定窗口大小的滑动窗口方法。

### Convolutional neural network

我们提出了基于CNN的Max-Feature-Map激活的欺骗检测方法。 MFM功能定义为

￥这里是公式￥

其中x是大小为H×W×N的输入张量，y是大小为H×W×N 2的输出张量。 在此，i，j表示频域和时域，而k是信道索引。 图3说明了卷积层的MFM。 MFM的使用使我们可以减少CNN架构。 因此，这种CNN架构被称为Light CNN（LCNN）[16]。

与常用的通过阈值（或偏差）抑制神经元的整流线性单位函数相反，MFM通过竞争关系抑制神经元。 通过这样做，MFM发挥了功能选择器的作用。

我们使用了[16]中提出的CNN的简化版本，每层中的滤波器数量更少（请参见表1）。 CNN包括5个卷积层，4个网络中网络（NIN）层[21]，10个最大特征图层，4个最大池化层和2个完全连接层。

每个卷积层都是根据层的输入计算得出的两个独立卷积部分的组合。 然后使用Max-FeatureMap激活函数来计算这些零件的逐元素最大值。 内核尺寸为2×2，步幅为2×2的Max-Pooling层可同时用于减少时间和频率尺寸。 全连接（FC）FC6层包含低维的高级音频表示。 然后使用具有softmax激活功能的FC7层在训练过程中区分真实和欺骗类。

描述的CNN用于获取高级音频功能。 简单的基于GMM的分类器（请参阅第2节）可用于在评估时区分低维空间中的真实和欺骗类。

### 堆叠卷积神经和递归神经网络

在工作[11]之后，我们使用组合的CNN + RNN体系结构。 这种集成的主要思想是将CNN用作特征提取器，而RNN对长期依赖关系进行建模。 CNN和RNN都是通过反向传播共同优化的，是端到端解决方案。 总体架构如表2所示。

与3.2中的LCNN不同，max-pooling操作是使用沿频率轴的大小为2的跨度压缩频率信息，以及沿时间轴的大小为1的跨度来节省时间维数的。 CNN的输出包含8个大小为32×400的通道。

RNN部分由两个门控循环单元[22]组成，该单元形成了双向门控循环单元（BGRU）。 第一个GRU负责前向传递，并处理从第一个输入向量到最后一个输入向量的数据。 第二个GRU处理从最后一个输入向量到第一个向后传递的数据。 向前和向后通行的最后输出向量被进一步取用以获得两个16维向量。 这种BGRU单元应用于CNN输出的每个通道，从而产生16×2×8张量。 权重在每个渠道的单位之间共享，以防止过拟合。 BGRU的示意图如图4所示。

RNN的平展输出用作通过MFM激活的完全连接层的输入，从而导致话语被欺骗的可能性。

## Experimental setup

## Datasets

这项工作中的所有实验均在ASVspoof 2017数据集上进行。 这些数据集的详细描述可以在[6]中找到。 为了训练本文考虑的所有系统，我们仅使用了训练部分。 开发部分用于系统融合的性能验证和权重调整。 评估部分包括新发言人，环境，重放记录设备组合以及新颖的攻击，这些攻击与培训和开发人员的攻击有很大不同。 因此，在评估部分对建议的系统进行比较最具代表性。

### Details of systems implementation

基线。 ASVspoof基线系统使用29 CQCC，0阶倒谱系数以及一阶和二阶导数。 对于后端部分，使用带有随机初始化的期望最大化（EM）算法，分别针对真实语音和欺骗语音训练了两个512分量GMM模型。

SVM i矢量。 在基于i向量的基线系统中，我们使用了汉宁窗函数获得的78个LPCC系数，窗函数为0.128秒，步长为0.016秒，用于FFT功率谱估计[23]。 在该系统中，使用了128分量对角协方差UBM，ivector的大小为200。将这些i-vector居中并进行长度归一化。 对于后端，我们将SVM分类器与线性核一起使用[24]。

LCNN。 我们比较了3个LCNN系统。 在LCNNF F T系统中，我们使用大小为864×400×1的截断归一化FFT频谱图作为LCNN第一卷积层的输入。

表1中描述了所用LCNN的体系结构。请注意，FC6层的矩阵非常大。 为了防止过度拟合，使用0.7比率的压差。 Xavier初始化用于卷积层[25]。 动量为0.9，学习率为10-4的ADAM优化器[26]用于训练过程。 由于在获得的高级特征空间中真实的和重播的欺骗类是可分离的，因此对每个类使用简单的高斯模型就足够了。

此外，我们在LCNNCQT系统中探索了基于CQT的功能，而不是FFT。

在LCNNSW F F T系统中，我们使用864×200×1大小的滑动窗口，沿时间轴重叠90％，以获得统一形状的FFT谱图。 在这种情况下，我们为每个窗口分别提取了高级功能。 对应于测试话语的所有高级特征都用于估计GMM似然比得分。

CNN + RNN。 该系统使用了从对数幅度FFT频谱中提取的截断特征。 由于计算资源有限，我们不得不减少CNN + RNN系统输入数据的大小。 使用Blackman窗口函数提取特征，窗口大小为256，步长为64。获得的CNN + RNN系统输入张量的大小为256×400×1。

## Results and discussion

表3列出了所有提到的系统得出的EER估算值（％）。 由于条件不同，开发和评估集上的结果差异很大。 在基准系统功能中使用MVN可以改善开发和评估集的欺骗检测质量。 i-vector基本系统在dev数据集上显示出与基线结果相当的结果，并证明了在评估部分“未知”条件下检测欺骗的稳定性。

通过使用FFT截断功能的单个LCNN系统，证明了dev和eval的最佳结果。 有趣的是，具有基于CQT的功能的类似系统在评估集上显示出较差的稳定性，这可能是由于CQT功能的较差的鲁棒性所致。 基线系统的结果也证明了这一点。

与评估集上的截断方法相比，滑动窗口技术显示出较差的结果。 造成这种情况的可能原因是，将整个话语的频谱图（在大多数情况下）用作CNN输入会导致更准确的文本相关深度模型。 我们将RNN与CNN结合使用的版本也比单个LCNN表现差。 我们通过频谱估计中降低的频率分辨率来解释性能下降。

我们在ASVspoof 2017挑战赛上提出的主要系统是LCNNF F T，SV Mi-vect和CNNF F T + RNN系统在分数级别的融合[27]。 该系统在dev和eval集合上分别显示了3.95％EER和6.73％EER。

在CNN训练过程中，我们对频域感兴趣，该频域对于真正的和重播的语音分离更加有用。 事实证明，在频谱下半部分（从0到4000 Hz）的情况下，dev数据集上欺骗检测的精度达到了68％。 在较高频段（从4000到8000 Hz）的情况下，我们在相同的验证集上达到了85％的准确度。

我们建议，与针对所有短语训练的系统相比，短语相关的系统可以执行更高的准确性。 我们使用来自训练部分的数据，独立检查了针对多个不同短语训练的基于LCNNF F T和i向量的系统。 但是，我们的实验表明，与在挑战数据的整个训练部分上训练的通用系统相比，欺骗检测的减少。 这可以通过在短语相关的情况下由于训练数据的大小不足而快速过拟合来解释。

## Conclusions

在本文中，我们探索了深度学习方法在解决重放攻击欺骗检测问题方面的适用性。 我们研究了单个CNN，并结合了RNN方法。 我们在ASVspoof 2017数据集上进行的实验证实了“在野外”进行欺骗检测的深度学习框架的高效性。 最佳单个CNN系统的EER为7.34％。 我们基于系统分数融合的主要系统在评估集上提供了6.73％的EER。